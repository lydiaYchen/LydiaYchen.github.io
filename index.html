---
layout: page
css:
  - /assets/css/index.css
js:
  - /assets/js/index.js
cover-img:
  - "assets/img/Banner2.jpg" : "Dolomiti"
  - "assets/img/Banner3.jpg" : "Switzerland"
  - "assets/img/Banner4-Greina.jpg" : "Greina Plateu, Switzerland"
  - "assets/img/Banner5-Buc.jpg" : "Brač, Croatia"
title: Lydia Y. Chen
subtitle: Distributed Machine Learning Lab
---

<style>
    .div-1 {
        background-color: #eff1f0;
    }
    
</style>

I am a professor at <strong>University of Neuchatel</strong> and <strong>TU Delft</strong>. I am the director of Distributed Learning Systems Lab. I returned to academia, after a decade of industry experience at the <strong>IBM Research Zurich Lab</strong>.  My research interests lie in the distinct areas of deep machine learning, big data systems, and privacy enhancing technology.  My research is supported by the Swiss National Science Foundation, Dutch National Science Foundation the European Union, IBM Research,  ABB, TU Delft, Aegon, Tata Steel, and ASML. My recent research focuses on generative AI and distributed machine learning algorithms and systems leads me to address following exciting research areas and questions.
 <!-- 
<br>
<br>
My recent research focuses on generative AI and distributed machine learning algorithms and systems leads me to address following exciting research areas and questions.
-->
<br>
<br>
I have multiple  <strong>open PhD positions</strong>. If you are interested in them, please drop me an email at lydiaychen@ieee.org.

<br>
<br>

<li> Generative AI systems:
how to discover the unnkown via the power of generative models, ranging from tables, time series to graph? I am exploring large langague models and diffusion models in collaboration with scientiest in natural science and manufactoring.
<li> Privacy-preserving learning systems by synthetic data: 
how to maximize the knowledge of  while maintaining data privacy ? I am combining the deep generative models and privacy-enhancing technologies as a privacy-preserving data sharing solution. </li>

<li>  Robust and privacy-preserving learning systems:
how to make learning algorithms robust against adversaries that maliciously manipulate data input? I am designing practical strategies and theories against attackers, e.g., free riders, and thief. </li>
 
<li >Federated machine learning systems:
how to decentralizedly learn deep learning models on heterogeneous clients who contentiously encounter new learning tasks and data domain shift? I am working on domain adaptation, and continual learning in FL. </li>

<br>
<br>

 <div class="div-1">
 <h2>News</h2>
 <li>[06/24] Our paper, <a href="">  Our group has three papers accepted at <a href="//"> SRDS 24</a></li>    
 <li>[04/24] Our paper, <a href="">  “Duwak: Dual Watermarks in Large Language Models" </a> , is accepted at <a href="//"> ACL 24</a></li>    
 <li>[02/24] Our paper, <a href="">  “SiloFuse: Cross-silo Synthetic Data Generation with Latent Tabular Diffusion Models." </a> , is accepted in <a href="//"> ICDE 24</a></li>    
 <li>[02/24] Our paper, <a href="">  “ElasticDNN: On-Device Neural Network Remodeling for Adapting Evolving Vision Domains at Edge" </a> , is accepted in <a href="//"> IEEE Transactions on Computers</a></li>    
 <li>[01/24] Our paper, <a href="">  “DALLMi: Domain Adaption for LLM-Based Multi-label Classifier" </a> , is accepted in <a href="//"> PAKDD 24</a></li>    
 <li>[01/24] Our paper, <a href="">  “On Dark Knowledge for Distilling Generators" </a> , is accepted in <a href="//"> PAKDD 24</a></li>    

<li>[07/23] Lydia will serve NWO Open Competition assessment committee </li>
<li>[06/23] Our paper, <a href="">  “Exploring and Exploiting Data-Free Model Stealing" </a> , is accepted in <a href="//"> ECML 23</a></li>    
<li>[04/23] Our paper, <a href="">  “LeadFL: Client Self-Defense against Model Poisoning in Federated Learning" </a> , is accepted in <a href="//"> ICML 23</a></li>
<br>    
    
<a href="/axiv">Old News.....</a> 
 </div>

<br>
<br>
    
    <!-- 
<li>[03/23] Our paper, <a href="">  “Fabricated Flips: Poisoning Federated Learning without Data" </a> , is accepted in <a href="//"> DSN 23</a></li>
<li>[02/23] Our paper, <a href="">  “Maverick Matters: Client Contribution and Selection in Federated Learning" </a> , is accepted in <a href="//"> PAKDD 23</a></li>
<li>[01/23] Our paper, <a href="">  “Defending Against Free-Riders Attacks in Distributed Generative Adversarial Networks" </a> , is accepted in <a href="//"> Financial Crypto 23</a></li>
<li>[12/22] Our paper, <a href="">  “Robust Learning via Golden Symmetric Loss of (un)Trusted Labels
" </a> , is accepted in <a href="//"> SIAM SDM 23</a></li>
<li>[10/22] Our paper, <a href="">  “FedKNow:Federated Continual Learning with Signature Task Knowledge Integration at Edge" </a> , is accepted in <a href="//"> IEEE ICDE 23</a></li>

<li>[10/22] Our paper, <a href="">  “Permutation-Invariant Tabular Data Synthesis " </a>, is accepted in <a href="//"> IEEE Bigdata 22</a></li>
<li>[09/22] Our paper, <a href="">  “Trusted Loss Correction for Noisy Multi-Label Learning" </a>, is accepted in <a href="//"> ACML 22</a></li>
<li>[09/22] Our paper, <a href="">  “Multi Label Loss Correction against Missing and Corrupted Labels" </a>, is accepted in <a href="//"> ACML 22</a></li>
<li>[08/22] Our paper, <a href="">  “FreezOff: A Middleware for Heterogeneous Federated Learning Systems” </a>, is accepted in <a href="//"> Middleware 22</a></li>  
<li>[08/22] Our paper, <a href="">  “Community-based Approach to Gender-Constrained Influence Maximization" </a>, is accepted in <a href="//"> CIKM 22</a></li>
<li>[06/22] Our paper, <a href="https://arxiv.org/pdf/2204.13784.pdf">  “AGIC: Approximate Gradient Inversion Attack on Federated Learning" </a>, is accepted in <a href="//"> SRDS22</a></li>
<li>[06/22] Our paper, <a href="">  “Performance Modeling for Short-Term Cache Allocation" </a>, is accepted at ACM ICPP 2022</a></li>
-->

